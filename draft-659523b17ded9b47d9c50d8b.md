---
title: "Step-by-Step Guide to Installing and Running Dev Copilot AI  Locally"
slug: step-by-step-guide-to-installing-and-running-dev-copilot-ai-locally
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1704273113822/1dbaedab-f1d4-4da6-8ae4-4bcb87b32beb.png

---

## Introduction

In the ever-evolving world of software development, the integration of advanced tools and technologies is not just a luxury but a necessity. One such groundbreaking advancement is the use of large language models (LLMs) like ChatGPT, which have revolutionized how we approach coding and development. Imagine harnessing the power of an AI assistant right within your favorite Integrated Development Environment (IDE), Visual Studio Code (VS Code). This article delves into the exciting realm of setting up a local LLM integrated with VS Code to create a personalized, local Copilot AI development experience.

It's best to start the article with the result:

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1704272843665/8674bd46-57ad-45c0-ae51-c9685185fba9.png align="center")

We live in an era where AI is not just a buzzword but a practical tool at developers' fingertips. By setting up a local instance of an LLM, developers can ensure data privacy, customize the model to their specific needs, and work seamlessly without relying on cloud-based solutions. Integrating this local LLM with VS Code transforms how we write code, offering intelligent suggestions, automating repetitive tasks, and enhancing overall productivity.

This guide is designed for developers looking to step into the future of coding. Whether you're a seasoned developer or just starting, the fusion of a local LLM with VS Code opens up new horizons in software development. It explores how AI can become vital to your coding toolkit, helping you write better code faster and more accurately.

Join us as we embark on this journey to set up a local AI-powered coding assistant. You'll learn how to configure your local LLM, integrate it with VS Code, and unlock a new coding efficiency and creativity level. Let's dive in and transform your coding experience with the power of AI.

This will guide you through running your local copilot AI with LLM Garden - you can choose one [or all open-source LLMs from the model list](https://ollama.ai/library).

I'll focus on Windows 10/11 PCs because if you are a Mac or Linux user - you are already halfway there. I'll focus on CPU-only use cases. A separate article will cover GPU-powered cases.

## Prerequisites

We spoke about what you get, let's talk about what you need:

1. Admin access to your Windows 10 or 11
    
2. At least 16 GB of RAM
    
3. Basic knowledge of [Bash](https://www.freecodecamp.org/news/bash-scripting-tutorial-linux-shell-script-and-command-line-for-beginners/)
    
4. Installed VS Code
    

Let's go!

## Guide

### Step 1: Install Ubuntu 22.04 on Windows WSL2

The first step involves setting up Ubuntu 22.04 on Windows 10 or 11 using WSL2. WSL2 is a lightweight virtual machine that allows you to run a Linux kernel alongside your Windows OS. Follow the comprehensive guide on [Ubuntu's official tutorial](https://ubuntu.com/tutorials/install-ubuntu-on-wsl2-on-windows-10#1-overview) to get Ubuntu up and running on your system.

> Note. !!!! SUPER importent step !!!

Create file called `.wslconfig` in C:\\Users\\USER\_NAME folder, with content:

```ini
[wsl2]
memory=12GB
```

I recommend to allocate ~80% of available RAM to your WSL2 Ubuntu instance. LLMs are RAM-hungry.

> Note. !!!! SUPER importent step!!!

### Step 2: Installing Ollama on Ubuntu 22.04 in WSL2

Once you have Ubuntu installed, the next step is to install [Ollama](https://github.com/jmorganca/ollama). Ollama is a framework specifically designed to run large language models that power generative AI applications. To install Ollama, use the following command in your Ubuntu terminal:

```bash
curl https://ollama.ai/install.sh | sh
```

For detailed instructions and troubleshooting, visit the [Ollama GitHub page](https://github.com/jmorganca/ollama).

### Step 3: **Pulling CodeLllama:13b model**

Installing Node.js can be done similarly:

1. **Open Terminal**
    
2. **Run command**:
    
    ```bash
    ollama pull codellama:13b
    ```
    

### Step 4: Installing VS Code Copilot AI extension

Instal Ollama, you'll need to set up Node.js and [Ollama-Webui](https://github.com/ollama-webui/ollama-webui). Ollama-web provides a user interface to interact with the Ollama model garden. Follow these steps to launch the web interface:

1. **Open Visual Studio Code**: Launch your Visual Studio Code (VS Code) application on your computer.
    
2. **Access the Extensions View**: You can access the Extensions view by clicking on the sidebar's square icon or using the shortcut. `Ctrl+Shift+X` (on Windows/Linux) or `Cmd+Shift+X` (on macOS).
    
3. **Search for the Extension**: In the Extensions view search bar, type `Continue - CodeLlama` or go to full URL [https://continue.dev/](https://continue.dev/) to find the specific extension.
    
4. **Install the Extension**: Once you find the Copilot AI extension, click the 'Install' button. This will automatically download and install the extension into your VS Code.
    
5. **Reload if Necessary**: After the installation, you might need to reload VS Code to activate the extension.
    
6. **Configure Settings**: After installation, you NEED to configure the extension. Click on the extension icon on the left VS Code bar, then click on the gear in the bottom left corner.
    
    In the `models` array next block section:
    
    ```json
        {
          "title": "Ollama13",
          "provider": "ollama",
          "model": "codellama:13b"
        }
    ```
    
7. **Verify Installation**: To verify the installation, check that in the bottom left corner dropdown, you can choose `Ollama13` model.
    
8. **Try it**:
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1704273913106/05c9e4c2-97f1-4a28-86a3-f5fa0ae53dfa.png align="center")
    

## Model Garden

Ollama offers a lot of LLMs for you - look what it offers - [library (](https://ollama.ai/library)[ollama.ai](http://ollama.ai)[)](https://ollama.ai/library)!

## Conclusion

In this article, we've walked through setting up a local instance of a large language model integrated with Visual Studio Code. This powerful tool can revolutionize your coding experience, offering intelligent assistance, automating repetitive tasks, and significantly enhancing productivity. By utilizing an AI-powered coding assistant, you're stepping into the future of coding and ensuring data privacy and customization according to your specific needs. Whether you are a seasoned developer or just starting, the fusion of AI with your coding toolkit can help you write better code faster and more accurately. Remember, the world of AI is at your fingertips, ready to transform your software development journey.